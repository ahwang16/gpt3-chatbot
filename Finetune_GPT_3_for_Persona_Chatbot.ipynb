{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetune GPT-3 for Persona Chatbot",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/ahwang16/gpt3-chatbot/blob/master/Finetune_GPT_3_for_Persona_Chatbot.ipynb",
      "authorship_tag": "ABX9TyPySwzHXq0dxGXEQ4kelkg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahwang16/gpt3-chatbot/blob/master/Finetune_GPT_3_for_Persona_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning GPT-3 for a Persona Chatbot"
      ],
      "metadata": {
        "id": "obCnJHwsPufR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import Necessary Packages"
      ],
      "metadata": {
        "id": "13B9U9HsP1Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "HplcRYciB_3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "DwlCwqyMEK_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OWUvvrxcs3RK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "In the left toolbar, click on the \"Files\" icon and then \"Mount Drive.\"\n",
        "\n",
        "Add this [folder](https://drive.google.com/drive/folders/1hpNqap_zPdWCYAMMz7L25w5kI7m2w9MP?usp=sharing) to your Drive and then update the path below."
      ],
      "metadata": {
        "id": "kDAcOe1xuzEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/1 Penn Academics/2021-2022/CIS 810/Implementation/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDRvdvUjt4wX",
        "outputId": "355ec560-b01c-49c0-d59c-b9b5e810bf26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/1 Penn Academics/2021-2022/CIS 810/Implementation/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The path here should match the path to your Data folder above.\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYzMZUci0OuT",
        "outputId": "1da8da0d-b6d6-4852-f0bf-4550153d9161"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/1 Penn Academics/2021-2022/CIS 810/Implementation/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_dialogue_path = \"light_dialogue_data_train.jsonl\"\n",
        "\n",
        "with open(light_dialogue_path, \"r\") as infile:\n",
        "  light_dialogue = json.load(infile)"
      ],
      "metadata": {
        "id": "2C1MqO-Au2vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Fine-Tuning Data"
      ],
      "metadata": {
        "id": "MH1EcMHaCRsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(idx):\n",
        "  agents = light_dialogue[idx][\"agents\"]\n",
        "  prompt = \"The following is a conversation between {} and {}.\\n\".format(\n",
        "      agents[0][\"name\"], agents[1][\"name\"]\n",
        "  )\n",
        "\n",
        "  return prompt\n",
        "\n",
        "\n",
        "def create_completion(idx):\n",
        "  character = light_dialogue[idx][\"character\"]\n",
        "  speech = light_dialogue[idx][\"speech\"]\n",
        "\n",
        "  dialogue = \"\"\n",
        "\n",
        "  for i in range(len(speech)):\n",
        "    dialogue += \"{}: {}\\n\".format(character[i], speech[i])\n",
        "\n",
        "  dialogue += \"###\\n\"\n",
        "\n",
        "  return dialogue\n",
        "\n",
        "\n",
        "def create_finetuning_data():\n",
        "  finetuning_data = []\n",
        "\n",
        "  for i in range(len(light_dialogue)):\n",
        "    if len(light_dialogue[i][\"speech\"]) > 1:\n",
        "      data = {}\n",
        "      data[\"prompt\"] = create_prompt(i)\n",
        "      data[\"completion\"] = create_completion(i)\n",
        "      finetuning_data.append(data)\n",
        "\n",
        "  print(len(finetuning_data))\n",
        "  for example in finetuning_data[:10]:\n",
        "    print(example[\"prompt\"])\n",
        "    print(example[\"completion\"])\n",
        "\n",
        "  with open(\"light_dialogue_finetuning.jsonl\", \"w\") as outfile:\n",
        "    for data in finetuning_data:\n",
        "      outfile.write(json.dumps(data) + \"\\n\")"
      ],
      "metadata": {
        "id": "2CoQfaPk5oEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_finetuning_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe5bDi-N8Fm6",
        "outputId": "a9e5378c-2b21-4530-8efd-903e50ca298d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9807\n",
            "The following is a conversation between court wizard and soldier.\n",
            "\n",
            "court wizard: A quiet night this evening...\n",
            "soldier: yes it is\n",
            "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
            "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
            "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
            "soldier: I am a soldier doing my job\n",
            "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
            "soldier: No sir\n",
            "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
            "soldier: A year ago, Test it out or cause a need to use it\n",
            "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
            "soldier: Good idea, I agree, go do that\n",
            "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
            "soldier: To the jail with you\n",
            "###\n",
            "\n",
            "The following is a conversation between thief and person.\n",
            "\n",
            "thief: Hey, you orc, get out of here.\n",
            "person: I'm no orc. I'm just a homeless man\n",
            "thief: I'm sorry, I thought you were someone else. Can I buy you a beer?\n",
            "person: That would be so kind. I am so hungry and have been feeling sick.\n",
            "thief: Oh, I don't have enough money to do that. Sorry, I need to leave.\n",
            "person: I should have known even a thief would look down on me.\n",
            "thief: I have to go.\n",
            "person: What's that in your pocket?\n",
            "thief: It's a book I like to read sometimes.\n",
            "person: Who did you steal it from?\n",
            "thief: I didn't steal it from anyone. Listen, I don't want a fight.\n",
            "person: Neither do I. I'm just desperate for a bite to eat.\n",
            "thief: Sorry.\n",
            "person: Where are you going?\n",
            "###\n",
            "\n",
            "The following is a conversation between witch and fairy.\n",
            "\n",
            "witch: What brought you to this desolate place?\n",
            "fairy: I've got no desire to be here. I was taken against my will. I haven't even given a wish yet.\n",
            "witch: It is cold here. I'm sorry to hear of how things have turned out for you. \n",
            "fairy: Thank you...But what about the princess over there?\n",
            "witch: I wonder if I can use my spell book to cheer her up. There must be a spell in there for that. Without access to the world outside to get the ingredients for my potions, we might struggle. \n",
            "fairy: Can you do anything with this? Fire and wax? That's gotta be something.\n",
            "witch: Perhaps, but many of the charms require berries and herbs. It doesn't hurt to try. You mentioned about your wish, can you grant one to anyone?\n",
            "fairy: Only humans. And you'd have to find me first! It's no fair that I'm locked in here,\n",
            "witch: It is a sorry state of affairs, as the look on the princess' face testifies. At least I have Felix. He is my familiar. Still he has only has that dirty old bucket to scratch his back on, and that isn't good for his health. \n",
            "fairy: Still, there's got to be a way out of here. I've got a family, I can't leave them behind! But this lantern isn't helping, I gotta let it down. Speaking of, can that cat fit through the bars? Maybe we could float him down somehow.\n",
            "witch: Can the dirty wooden bucket help?\n",
            "fairy: Maybe. Maybe we could fit the cat in it and lower the bucket down somehow. Could you use magic or something?\n",
            "witch: Here you go, if I give you the bucket then I can see you. Then could I catch you and get the wish?\n",
            "fairy: Yeah, that's an idea. You close your eyes or something and I'll hide in the bucket somewhere. If you can find me, I think I can give you a wish.\n",
            "###\n",
            "\n",
            "The following is a conversation between guard and prisoner.\n",
            "\n",
            "guard: You, prisoner. The king wishes to see you.\n",
            "prisoner: What for?\n",
            "guard: The king wishes to make a deal with you. Beyond me why he cares for a prisoner.\n",
            "prisoner: Thank heavens, I thought I would never see my family again.\n",
            "guard: Don't be so hasty. The king might ask more of you than you think.\n",
            "prisoner: At least I'll have a chance to explain myself.\n",
            "guard: You do that. But remember you were put in the dungeon for good cause.\n",
            "prisoner: I was placed here by mistake. They have me mixed up with another man!\n",
            "guard: They all tell me that. But this isn't my decision.\n",
            "prisoner: I understand. You are only doing your job.\n",
            "guard: At least you are cooperating. I'll mention that.\n",
            "prisoner: What have I been accused of doing?\n",
            "guard: You are accused of disobeying a direct order by the queen. As rigid as she is.\n",
            "prisoner: I don't remember being ordered by the queen to do anything.\n",
            "###\n",
            "\n",
            "The following is a conversation between the king and archer.\n",
            "\n",
            "the king: What are you doing here, archer?\n",
            "archer: An archer such as myself needs no reason to be at a nice place like this. \n",
            "the king: Since you are here, I need more wine. Please fill my glass immediately.\n",
            "archer: Yes sir, although you're under utilizing my ability with a bow and and arrow. What a lovely place you have here.\n",
            "the king: Thank you. My bed frame alone is more valuable than anything you've ever seen\n",
            "archer: A frame made from materials more valuable than my bow. Where would one acquire such a material?\n",
            "the king: That I cannot say. What do you hunt with your bow and arrow?\n",
            "archer: I hunt the enemy. I deal with those you consider unworthy. It's my most skilled practice. What else can I do for you?\n",
            "the king: Can you teach me how to use the weapon? \n",
            "archer: A skill like these is easy to learn but takes a lifetime to master. \n",
            "the king: I have always wanted to learn but was forbidden as a child.\n",
            "archer: That's outrageous. A child is more ready to learn than most. I will not neglect you like your parents have.\n",
            "the king: They were always afraid of any harm coming to their sole heir. I shall cherish our archery lessons.\n",
            "archer: Can I interrupt you for a moment to admire the gold tapestries on the walls? It resembles the material of your bed frame. Is your bed frame made of solid gold?\n",
            "###\n",
            "\n",
            "The following is a conversation between princess and troll.\n",
            "\n",
            "princess: What are you doing here, troll?\n",
            "troll: To pay your toll, pay the troll.\n",
            "princess: I don't have any money, but I need to cross the bridge to leave my horrible arranged marriage. I need to get supplies to run away with my love, the stable boy. Is there anything else I can do to cross?\n",
            "troll: Troll don't manage bridge for free. What you pay me? Maybe you have a ring?\n",
            "princess: I have a necklace of gems I can give you. It was given to me when I was born- there's a long tradition of this necklace being passed down to princesses in my family.\n",
            "troll: I will examine.\n",
            "princess: What do you say? Can I cross yet? I would rather not have to swim across these muddy waters... \n",
            "troll: What else you have for troll?\n",
            "princess: Maybe I can solve a riddle? \n",
            "troll: If you can figure out what troll want most you are free to pass.\n",
            "princess: Can you tell me what you want so we can both be done with this? \n",
            "troll: I show you.\n",
            "princess: How dare you!\n",
            "troll: Troll just want love.\n",
            "###\n",
            "\n",
            "The following is a conversation between field mice and garter snake.\n",
            "\n",
            "field mice: You haven't seen any cats around here, have you?\n",
            "garter snake: No, but I am feeling a bit peckissssh... \n",
            "field mice: This tack for the work horses doesn't tickle your fancy I suppose?\n",
            "garter snake: Sssurely you jest... What ussse have I for such a trinket. You seem quiet... ssstrong... for a mouse\n",
            "field mice: It is only necessity! I knock it hither and thither but I am so frightened of cats that I have to use things like this to hide under! \n",
            "garter snake: You should sssspeak to a girl on the edge of the village.  Her demonssss she summons would frighten away any such pestsssss.\n",
            "field mice: Maybe you could give this tack for the work horses to a horse. They could then prop open the barn doors and hey presto! You can go and get food and I can speak to the girl from the village!\n",
            "garter snake: Hm, it isss an interessssting idea.  You are too small a meal for me, but a ssssnack.  A nice fat rat... yessss... if I could get out and find one...\n",
            "field mice: Yeah I am just lil Vole. You need something big and tasty.  Thank you for liking the idea. Shall we go ahead with it? \n",
            "garter snake: Hm you do ssssmell so nice and warm... but yesss.. it is in agreement.  I am Anguisssss.  If you but sssspeak my name when you arrive, I am sure the demon will be yourssss\n",
            "field mice: Thank you Anguisssss. It is a plan. \n",
            "garter snake: How did you come to be in thisss barn full of catsss? \n",
            "field mice: I like that it is far away from the Farm house where the cats tend to congregate! So lil Vole comes here to chill, but I know that I can't stay here forever because cats run around wherever they like: the field, the barn, the house. \n",
            "garter snake: Yesss, they do sometimes ssssteal the rats that are rightfully mine.  They have no ressspect, none at all.\n",
            "###\n",
            "\n",
            "The following is a conversation between cockroach and firemen.\n",
            "\n",
            "cockroach: I wonder if there is any bread here?\n",
            "firemen: look out there is a cockroach on the bread\n",
            "cockroach: Take that! \n",
            "firemen: feel my power\n",
            "cockroach: It's rough, but I can survive any...thing...\n",
            "firemen: we'll see how much you can take \n",
            "cockroach: My family will be here long after your miserable species has been turned back to the soil and dust.\n",
            "firemen: We are more powerful than you and will win the war against your kind\n",
            "cockroach: If my kind goes, your kind cannot long survive... Is that delicious glue on your helmet? I haven't had that in a LONG time! Heading in for a snack... BAM!\n",
            "firemen: get off me you rotten smelly cockroach\n",
            "cockroach: If you will chill out and help me find some scraps, I can help you get the Enchanted torch so you can escape. I can leave here any time I feel like!\n",
            "firemen: perhaps we should learn to work together\n",
            "cockroach: Yes, let us freak out some squares now and get the Enchanted Torch!\n",
            "firemen: thank you for offering to help me acquire the enchanted torch. From this day forward we will be friends instead of enemies\n",
            "###\n",
            "\n",
            "The following is a conversation between villager and homeless man.\n",
            "\n",
            "villager: Oh hello, I didn't expect to find anyone else here.\n",
            "homeless man: Hi, I didn't either, but a man could use the company in a place like this.\n",
            "villager: Are you looking for something here?\n",
            "homeless man: Mainly a dry place to sleep, a place that isn't always wet and cold, like I usually have to sleep. Are you?\n",
            "###\n",
            "\n",
            "The following is a conversation between mice and knight.\n",
            "\n",
            "mice: Can you spare some cheese?\n",
            "knight: I would love to give you some cheese because it would give me great honor to care for you, a member of this kingdom, although you are but mice.\n",
            "mice: You are so kind. Most people scream when they see me.\n",
            "knight: I am a knight, and it is my duty to be honorable! I am of noble blood, so of course I want to help you!\n",
            "mice: I am so delighted to not have to scavenge for food in the village.\n",
            "knight: But of course! I am happy to help. I'm glad I stumbled upon you here in the Knights Quarters. Now, don't let any of the king's royal guard see you! \n",
            "mice: I will hide behind that trunk\n",
            "###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tune the Model with the OpenAI API"
      ],
      "metadata": {
        "id": "3EqL2eiDRV7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, enter your OpenAI API key.\n",
        "You can find your key [here](https://beta.openai.com/account/api-keys). You will be prompted to enter your API key when you run the next cell."
      ],
      "metadata": {
        "id": "ylLXVTbBRaOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = getpass()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRS-HOhp-Obn",
        "outputId": "9ab6ea7a-a5e5-4224-ffb6-2ae776810ab6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next, run the fine-tuning command.\n",
        "In our case, we are specifying `light_dialogue_finetuning.jsonl` as the fine-tuning data file and `curie` as the base model we want to fine-tune."
      ],
      "metadata": {
        "id": "syi9aJXgRp-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t light_dialogue_finetuning.jsonl -m curie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5ISEwATCvdl",
        "outputId": "b42fb258-9af4-4e29-842c-584f5352b0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/12.5M [00:00<?, ?it/s]\rUpload progress: 100% 12.5M/12.5M [00:00<00:00, 20.2Git/s]\n",
            "Uploaded file from light_dialogue_finetuning.jsonl: file-EGwZldxTV3nryjY0ou8PFESi\n",
            "Created fine-tune: ft-REphHUyNJeAIUCSdHnI82xzW\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2022-07-31 21:42:39] Created fine-tune: ft-REphHUyNJeAIUCSdHnI82xzW\n",
            "[2022-07-31 21:42:49] Fine-tune costs $37.56\n",
            "[2022-07-31 21:42:50] Fine-tune enqueued. Queue number: 0\n",
            "[2022-07-31 21:42:51] Fine-tune started\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-REphHUyNJeAIUCSdHnI82xzW\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: Restart streaming.\n",
        "Sometimes, the streaming output cuts off before fine-tuning is done. You can restart streaming by running the following command with the fine-tuning ID. All of this information is included in the output of the above fine-tuning command, too."
      ],
      "metadata": {
        "id": "nQCMzi2LSHCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-REphHUyNJeAIUCSdHnI82xzW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5o5UkzWE_5B",
        "outputId": "cb07475f-011b-44c7-8a32-333c1bcfec4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-07-31 21:42:39] Created fine-tune: ft-REphHUyNJeAIUCSdHnI82xzW\n",
            "[2022-07-31 21:42:49] Fine-tune costs $37.56\n",
            "[2022-07-31 21:42:50] Fine-tune enqueued. Queue number: 0\n",
            "[2022-07-31 21:42:51] Fine-tune started\n",
            "[2022-07-31 21:54:06] Completed epoch 1/4\n",
            "[2022-07-31 22:04:25] Completed epoch 2/4\n",
            "[2022-07-31 22:14:46] Completed epoch 3/4\n",
            "[2022-07-31 22:25:05] Completed epoch 4/4\n",
            "[2022-07-31 22:25:29] Uploaded model: curie:ft-ccb-lab-members-2022-07-31-22-25-29\n",
            "[2022-07-31 22:25:30] Uploaded result file: file-UPDNOfeEyr261DngZLU9o5xN\n",
            "[2022-07-31 22:25:30] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m curie:ft-ccb-lab-members-2022-07-31-22-25-29 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You're done!\n",
        "Great, you're now done fine-tuning GPT-3 for a persona chatbot! Head over to the [OpenAI Playground](https://beta.openai.com/playground) to try your new model."
      ],
      "metadata": {
        "id": "EFqB2RwtS65l"
      }
    }
  ]
}